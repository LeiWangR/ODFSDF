{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class SoundNet8_pytorch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SoundNet8_pytorch, self).__init__()\n",
    "        \n",
    "        self.define_module()\n",
    "        \n",
    "    def define_module(self):\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1,16, (64,1), (2,1), (32,0), bias=True),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((8,1), (8,1))\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, (32,1), (2,1), (16,0), bias=True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((8,1),(8,1))\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, (16,1), (2,1), (8,0), bias=True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, (8,1), (2,1), (4,0), bias=True),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, (4,1),(2,1),(2,0), bias=True),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((4,1),(4,1))\n",
    "        ) \n",
    "        # difference here (0.24751323, 0.2474), padding error has beed debuged\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, (4,1), (2,1), (2,0), bias=True),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv7 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, (4,1), (2,1), (2,0), bias=True),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv8 = nn.Sequential(\n",
    "            nn.Conv2d(1024, 1000, (8,1), (2,1), (0,0), bias=True),\n",
    "        ) \n",
    "        self.conv8_2 = nn.Sequential(\n",
    "            nn.Conv2d(1024, 401, (8,1), (2,1), (0,0), bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        for net in [self.conv1, self.conv2, self.conv3, self.conv4, self.conv5, self.conv6, self.conv7]:\n",
    "            x = net(x)\n",
    "            print('xxxxxx', x.shape)\n",
    "        object_pred = self.conv8(x)\n",
    "        scene_pred = self.conv8_2(x)\n",
    "        print('------', object_pred.shape, scene_pred.shape)\n",
    "        return object_pred, scene_pred\n",
    "\n",
    "    def extract_feat(self,x:torch.Tensor)->list:\n",
    "        output_list = []\n",
    "        for net in [self.conv1, self.conv2, self.conv3, self.conv4, self.conv5, self.conv6, self.conv7]:\n",
    "            x = net(x)\n",
    "            output_list.append(x.detach().cpu().numpy())\n",
    "        object_pred = self.conv8(x)\n",
    "        output_list.append(object_pred.detach().cpu().numpy())\n",
    "        scene_pred = self.conv8_2(x) \n",
    "        output_list.append(scene_pred.detach().cpu().numpy())\n",
    "        return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxxxxx torch.Size([1, 16, 884592, 1])\n",
      "xxxxxx torch.Size([1, 32, 55287, 1])\n",
      "xxxxxx torch.Size([1, 64, 27644, 1])\n",
      "xxxxxx torch.Size([1, 128, 13823, 1])\n",
      "xxxxxx torch.Size([1, 256, 1728, 1])\n",
      "xxxxxx torch.Size([1, 512, 865, 1])\n",
      "xxxxxx torch.Size([1, 1024, 433, 1])\n",
      "------ torch.Size([1, 1000, 213, 1]) torch.Size([1, 401, 213, 1])\n",
      "original input dim.:  (14153472,) reshaped input dim.:  torch.Size([1, 1, 14153472, 1])\n"
     ]
    }
   ],
   "source": [
    "model = SoundNet8_pytorch()\n",
    "\n",
    "input_data = np.load('demo.npy')\n",
    "x = torch.from_numpy(input_data).view(1,1,-1,1)\n",
    "model(x)\n",
    "\n",
    "print('original input dim.: ', input_data.shape, 'reshaped input dim.: ', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  9 in the list\n",
      "(1, 16, 884592, 1)\n"
     ]
    }
   ],
   "source": [
    "# feature extraction and further analysis\n",
    "sound_feat = model.extract_feat(x)\n",
    "print('There are ', len(sound_feat), 'in the list')\n",
    "\n",
    "print(sound_feat[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxxxxx torch.Size([1, 16, 82157, 1])\n",
      "xxxxxx torch.Size([1, 32, 5134, 1])\n",
      "xxxxxx torch.Size([1, 64, 2568, 1])\n",
      "xxxxxx torch.Size([1, 128, 1285, 1])\n",
      "xxxxxx torch.Size([1, 256, 160, 1])\n",
      "xxxxxx torch.Size([1, 512, 81, 1])\n",
      "xxxxxx torch.Size([1, 1024, 41, 1])\n",
      "------ torch.Size([1, 1000, 17, 1]) torch.Size([1, 401, 17, 1])\n"
     ]
    }
   ],
   "source": [
    "# generate a fake sound waveform\n",
    "fake_input = np.random.rand(1, 1, 1314520, 1)\n",
    "model = model.double()\n",
    "fake_feat = model(torch.from_numpy(fake_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "# NOTE: Load an audio as the same format in soundnet\n",
    "# 1. Keep original sample rate (which conflicts their own paper)\n",
    "# 2. Use first channel in multiple channels\n",
    "# 3. Keep range in [-256, 256]\n",
    "\n",
    "def load_audio(audio_path, sr=None):\n",
    "    # By default, librosa will resample the signal to 22050Hz(sr=None). And range in (-1., 1.)\n",
    "    sound_sample, sr = librosa.load(audio_path, sr=sr, mono=False)\n",
    "\n",
    "    return sound_sample, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_sample, sr = load_audio('audio.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2748077)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sound_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ..., -0.00595093,\n",
       "        -0.00543213, -0.00506592],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.00387573,\n",
       "        -0.00372314, -0.00363159]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sound_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
